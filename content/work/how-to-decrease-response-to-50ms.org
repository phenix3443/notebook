# -*- coding:utf-8-*-
#+TITLE: 后台服务优化流程
#+AUTHOR: liushangliang
#+EMAIL: phenix3443+github@gmail.com

* 效果
  1. 完善服务监控和告警系统。
  2. 最复杂的接口响应从之前的 1-2s，降低到现在的 100ms 以内。
  3. 数据库内存从高峰期的 13-14Gb，缩减到当前的 1Gb 以内。
  4. 代码重构，实现代码模块化、补全单元测试，接口测试，补充项目文档和代码文档。

* 业务代码
  + 集成 ELK 数据采集和钉钉群告警，补全监控和告警系统有利于后续的业务开发和代码重构。
  + 接口处理流程规范化。所有处理流程规范为解析参数->请求处理->返回响应，使得处理逻辑更加清晰。
  + 设计接口对应的 =request= 和 =response= 结构体，好处：
    + 替代原先滥用的 =map[string]interface{}= ，该结构使用发射进行类型转换，低效。
    + 结构清晰明了，可以和代码文档相对应，也便于日志打印时候直接序列化，发送到 ELK 系统定位问题。
  + 拆分处理函数，这么做有两个优点：
    + 判断逻辑冗余在一个函数中，不便于阅读和测试，拆分成模块更便于复用和进行单元测试。
    + 耦合太紧的函数不利于 goroutine，提高并发。
  + 原先通过 for 循环过滤大量数据库查询结果，现在将限制条件放置在 sql 查询语句中，并将结果缓存在包含查询条件的 key 中。
  + 整个处理过程只使用代表书籍的 coopID_bookID，只在需要返回书籍信息的时候的时候查询书籍详情。
  + 将数据库和缓存模块单独拆分，增加一层接入层，向业务代码屏蔽底层数据结构。
    + 方便替换别的数据库。
    + 方便测试数据库代码。
  + 使用 zap 替代代低效的 fmt.Printf 写日志。
    + fmt.Printf 低效，没有日志分级，不仅日质量大，而且不方便定位问题。
    + 日志组件利用 zap 不仅打印高效，还可将运行日志和数据日志分离为不同的日志文件。操作日志对接 ELK 定位问题， 数据日志对接数据平台生成报表。

  + 程序本地缓存书籍静态信息。

  + 采用更加高效的 gin 替代 beego 框架。

  + 使用协程实现并行处理。

  + 异步处理，书籍入库异步处理，章节更新，查版权，屏蔽，消息队列。

* 缓存
  1. 书籍封面放在阿里云 CDN 上，加速客户端访问。
  2. 服务本地缓存书籍静态信息。
  3. 使用合理的数据结构。例如使用 set 存储分类信息，使用 zset 存储排行信息，二者做交集就是分类的排行信息。
  4. redis 只缓存书籍的动态信息，例如更新时间，最新章节等。
  5. 设置合理的 key 名，将过滤条件包含在 key 中，方便查询。
  6. 合理设置缓存的过期时间。


* 数据库（MySql）
  1. 合理设置设计表结构。
     + 比如推荐表中的有书籍信息相关的无效字段。
     + bookCate 表与 bookInfo 表需要联合查询，优化时候就把 bookInfo 表中的信息插入到 bookCate 表中，避免 join 操作。

  2. 使用合适的数据类型，例如使用 set\enum 存储移动端类型，用户性别等。

  3. 优化索引。
     + 联合索引排序，将 coop_bookID 索引为 bookID_coop，因为 bookID 的区分度更高。
     + 使用 FULLTEXT 替换原有正则表达式查询作者简介查询，后期替换为 es 进行模糊匹配。
     + 查询条件使用覆盖索引避免回表操作，使用索引下推提过查询效率。

  4. 使用查询优化程序和慢查询日志查找问题和验证优化结果。


* 其他
  1. 代码仓库遵循 golang 规范构建，这样别的项目也能引用我们的代码。
  2. 使用 go mod 替代 vender。
  3. 给出支付服务解决用户订单并发处理的方法：
     + 序列化请求，然后使用 pod 对接请求序列。
     + 使用 redis 实现分布式锁，处理时对用户进行加锁。
     + 使用 nginx 将用户请求 hash(userid)到业务机器，业务机器串行处理请求，这种方式对现有代码改动最小。
